# The name of LLM model to use.
MODEL=gpt-4.1

# Name of the embedding model to use.
EMBEDDING_MODEL=text-embedding-3-large

# The questions to help users get started (multi-line).
# CONVERSATION_STARTERS=

# The OpenAI API key to use.
OPENAI_API_KEY=sk-svcacct-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# Temperature for sampling from the model.
# LLM_TEMPERATURE=

# Maximum number of tokens to generate.
# LLM_MAX_TOKENS=


# Whether to suggest next questions (`suggestNextQuestions`)
SUGGEST_NEXT_QUESTIONS=true

# Directory for custom components (`componentsDir`)
COMPONENTS_DIR=components

# The path to the workflow file (will be updated in dev mode)
WORKFLOW_FILE_PATH=app/api/chat/app/workflow.ts

# Whether to enable components directory feature on frontend
NEXT_PUBLIC_USE_COMPONENTS_DIR=true

# Whether to enable dev mode (`devMode`)
NEXT_PUBLIC_DEV_MODE=true

# Initial questions to display in the chat (`starterQuestions`)
NEXT_PUBLIC_STARTER_QUESTIONS=["Summarize the document", "What are the key points?"]

# Whether to show LlamaCloud selector for frontend (`llamaCloudIndexSelector`)
NEXT_PUBLIC_SHOW_LLAMACLOUD_SELECTOR=false
